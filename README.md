# GDDP

Generalized dual dynamic programming (GDDP) tool written in Python. This tool creates an approximate lower bounds on a given control problem's optimal value function using the Benders decomposition approach developed in [1].

## Getting Started

Make a system, either by specifying a system's dynamics via a `model_dict`, or by calling on one of the preset systems hard-coded in the definition of class `System`.

```python
from gddp import System, VFApproximator
sys1 = System(name='Simple 1D system', model_preset='1D')
```

The `System` object carried not only the dynamics and constraints of the system itself, but also the stage cost function and discount factor.

You can now pass this system to a `VFApproximator` object, and create an approximation of the problem's value function:

```python
vfa = VFApproximator(system=sys1)
vfa.create_vfa_model()
vfa.approximate()
```

By default, this performs the Benders decomposition algorithm at 100 randomly-chosen points in the state space, normally distributed about the origin.

The routine creates a number of output files that contain information on the value function created.

### Q functions

Some functionality also exists for working with Q functions, which are defined on state-action space rather than the state alone. The syntax is the same:

```python
from gddp import QFApproximator
qfa = QFApproximator(system=sys1)
qfa.create_qfa_model()
qfa.approximate()
```

## Output format

The function `print_function_approximation()` prints, and optionally saves to a text file, an explicit representation in string form of the final value function.

The function `save_function_approximation()` creates a .mat file containing the constant, linear, and quadratic components of the lower-bounding functions that define the V- or Q-function approximation.

Example usage:

```python
vfa.print_function_approximation(command_line=True, save=False)
vfa.save_function_approximation()
```

The .mat file generated by the latter function contains the following entries, where _I_ is the number of GDDP iterations that added a lower bounding function, _n_ is the state dimension, and _m_ is the input dimension:

Function saved | Variable | Dimension | Description
---------|----------|-----------|------------
V | g_const | ( _I_+1, 1) | Constant component of VF lower bounding function
V | g_lin | ( _I_+1, _n_) | Linear component of VF lower bounding function
V | g_quad | ( _I_+1, _n_, _n_) | Quadratic (Hessian) component of VF lower bounding function
Q | q_const | ( _I_+1, 1) | Constant component of VF lower bounding function
Q | q_x_lin | ( _I_+1, _n_) | Linear x component of VF lower bounding function
Q | q_x_quad | ( _I_+1, _n_, _n_) | Quadratic (Hessian) x component of VF lower bounding function
Q | q_u_lin | ( _I_+1, _m_) | Linear u component of VF lower bounding function
Q | q_u_quad | ( _I_+1, _m_, _m_) | Quadratic (Hessian) u component of VF lower bounding function

## References

[1] J. Warrington, P. Beuchat, J. Lygeros, "Generalized Dual Dynamic Programming for Infinite Horizon Problems in Continuous State and Action Spaces", _IEEE Transactions on Automatic Control, to appear December 2019._

[2] J. Warrington, "Learning Continuous Q-Functions via generalized Benders cuts", _European Control Conference 2019, Naples, Italy, June 2019._
